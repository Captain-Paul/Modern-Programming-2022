利用python数据结构（list, dict, set等）完成简单的文本分析任务。
弹幕是现下视频网站，尤其是短视频网站提供的关键功能之一。
以B站为例，其有着特殊的弹幕文化，且在视频的不同部分往往会有不同话题的弹幕。
比如在视频开头会出 现“来啦”“x小时前”“第一!”;在up主暗示一键三连之后常常会出现“下次一定”或者“你币有 了”;
和up主建立默契之后，观众可以判断视频是否有恰饭，往往在广告之前会出现“要素察 觉”“恰饭”“快跑”等等。
因此，弹幕经常被作为测度用户（viewer）与视频作者（up主）之间交互行为的关键数据。
本次作业提供的数据来自B站某知名up主，已上传至课程资料的data目录下，数据格式说明如下。 
a. 弹幕文件：danmuku.csv，为2799000 rows × 3 columns，本次作业仅使用第一列，即弹幕的文本内容。 
b . 停用词表示例，stopwords_list.txt 请大家尝试完成以下数据分析任务： 
1. 使用danmuku.csv，其中一个弹幕可以视为一个文档（document），读入文档并分词（可以使用jieba或pyltp）。 
2. 过滤停用词（可用stopwords_list.txt，或自己进一步扩充）并统计词频，输出特定数目的高频词和低频词进行观察。
建议将停用词提前加入到jieba等分词工具的自定义词典中，避免停用词未被正确分词。
3. 根据词频进行特征词筛选，如只保留高频词，删除低频词（出现次数少于5之类），并得到特征词组成的特征集。 
4. 利用特征集为每一条弹幕生成向量表示，可以是0，1表示（one-hot，即该特征词在弹幕中是否出现）也可以是出现次数的表示（该特征词在弹幕中出现了多少次）。
注意，可能出现一些过短的弹幕，建议直接过滤掉。 
5. 利用该向量表示，随机找几条弹幕，计算不同弹幕间的语义相似度，可尝试多种方式，如欧几里得距离或者余弦相似度等，并观察距离小的样本对和距离大的样本对是否在语义上确实存在明显的差别。
请思考，这种方法有无可能帮助我们找到最有代表性的弹幕？ 
6. （附加）能不能对高频词（如top 50之类）进行可视化呈现（WordCloud包）？ 
7. （附加）能不能考虑别的特征词构建思路，如常用的TF-IDF，即一方面词的频率要高，另一方面，词出现的文档数越少越好，观察其与仅利用词频所得的结果有何差异，哪个更好？
8. （附加）了解一下word2vec等深度学习中常用的词向量表征（如gensim和pyltp中均有相关的库），并思考如果用这种形式的话，那么一条弹幕会被表示成什么形式？弹幕之间计算相似性的时候，会带来哪些新的问题？ 注意：不要使用jieba等库中提供的函数实现特征词抽取和文档表示，要求自己使用相关数据结构来实现；要通过函数对代码进行封装，并在main函数中调用。